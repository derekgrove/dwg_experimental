{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f272b23-433e-4dc6-99ca-6c1748a7bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/coffea/nanoevents/schemas/fcc.py:5: FutureWarning: In version 2025.1.0 (target date: 2024-12-31 11:59:59-06:00), this will be an error.\n",
      "To raise these warnings as errors (and get stack traces to find out where they're called), run\n",
      "    import warnings\n",
      "    warnings.filterwarnings(\"error\", module=\"coffea.*\")\n",
      "after the first `import coffea` or use `@pytest.mark.filterwarnings(\"error:::coffea.*\")` in pytest.\n",
      "Issue: coffea.nanoevents.methods.vector will be removed and replaced with scikit-hep vector. Nanoevents schemas internal to coffea will be migrated. Otherwise please consider using that package!.\n",
      "  from coffea.nanoevents.methods import vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cms-jovyan/dwg_experimental/src\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Step 1: Imports\n",
    "# ========================\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import dask\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "from coffea.dataset_tools import apply_to_fileset, max_chunks, max_files\n",
    "from dask.distributed import Client\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "#print(current_dir)\n",
    "#processors_dir = current_dir.parent / \"processors\"\n",
    "processors_dir = current_dir # used to keep processors separate but that was bad\n",
    "path_to_run_on = current_dir.parent\n",
    "path_to_master_json = current_dir.parent.parent / \"src\" / \"dataset_tools\"\n",
    "\n",
    "sys.path.append(str(processors_dir))\n",
    "\n",
    "processor_name = \"test_processor\" # without .py\n",
    "run_on_name = \"run_on_custom.json\"\n",
    "\n",
    "processor_module = importlib.import_module(processor_name)\n",
    "Processor = processor_module.Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef528e6e-0764-463f-92b6-5c5f041bb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(path_to_master_json / \"datasets_master.json\") as file:\n",
    "    datasets = json.load(file)\n",
    "\n",
    "with open(path_to_run_on / run_on_name) as file:\n",
    "    run_on = json.load(file)\n",
    "#print(run_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442f0622-21db-4b95-b737-8f241d2f1948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample in json: SlepSnu_MN1-260_MN2-280_MC1-270\n",
      "skipping\n",
      "sample in json: SlepSnu_MN1-220_MN2-260_MC1-240\n",
      "skipping\n",
      "sample in json: SlepSnu_MN1-270_MN2-280_MC1-275\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "QuickConstruct.Regular() missing 2 required positional arguments: 'start' and 'stop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m\n\u001b[1;32m     38\u001b[0m     tg, rep \u001b[38;5;241m=\u001b[39m apply_to_fileset(\n\u001b[1;32m     39\u001b[0m         data_manipulation\u001b[38;5;241m=\u001b[39mProcessor(),\n\u001b[1;32m     40\u001b[0m         fileset\u001b[38;5;241m=\u001b[39mtest_chunks,\n\u001b[1;32m     41\u001b[0m         schemaclass\u001b[38;5;241m=\u001b[39mNanoAODSchema,\n\u001b[1;32m     42\u001b[0m         uproot_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_read_errors_with_report\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m)},\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     tg, rep \u001b[38;5;241m=\u001b[39m \u001b[43mapply_to_fileset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_manipulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfileset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessed_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschemaclass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNanoAODSchema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43muproot_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow_read_errors_with_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mOSError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mKeyError\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#client.scheduler_info()\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample loaded, running, hold please.........\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/coffea/dataset_tools/apply_processor.py:127\u001b[0m, in \u001b[0;36mapply_to_fileset\u001b[0;34m(data_manipulation, fileset, schemaclass, uproot_options)\u001b[0m\n\u001b[1;32m    125\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m metadata\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[0;32m--> 127\u001b[0m dataset_out \u001b[38;5;241m=\u001b[39m \u001b[43mapply_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_manipulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschemaclass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muproot_options\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset_out) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    131\u001b[0m     out[name], report[name] \u001b[38;5;241m=\u001b[39m dataset_out\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/coffea/dataset_tools/apply_processor.py:82\u001b[0m, in \u001b[0;36mapply_to_dataset\u001b[0;34m(data_manipulation, dataset, schemaclass, metadata, uproot_options)\u001b[0m\n\u001b[1;32m     80\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_manipulation, ProcessorABC):\n\u001b[0;32m---> 82\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mdata_manipulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_manipulation, Callable):\n\u001b[1;32m     84\u001b[0m     out \u001b[38;5;241m=\u001b[39m data_manipulation(events)\n",
      "File \u001b[0;32m~/dwg_experimental/notebooks/class_testing/test_processor.py:69\u001b[0m, in \u001b[0;36mProcessor.process\u001b[0;34m(self, events)\u001b[0m\n\u001b[1;32m     59\u001b[0m electron \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mElectron\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#def_analysis = default_analysis(name=\"test\", pt=electron.pt)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#def_analysis = default_analysis(name=\"test\")\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#(obj, reg_binning, cat_binning, var_name = \"pt\", cat_name=\"genPartFlav\"):\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m test_hist \u001b[38;5;241m=\u001b[39m \u001b[43mmake_1d_pt_hist_cat\u001b[49m\u001b[43m(\u001b[49m\u001b[43melectron\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m output \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_entries\u001b[39m\u001b[38;5;124m\"\u001b[39m: ak\u001b[38;5;241m.\u001b[39mnum(events[events\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m#\"def_analysis\": def_analysis,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_hist\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_hist,\n\u001b[1;32m     77\u001b[0m }\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/dwg_experimental/notebooks/class_testing/test_processor.py:46\u001b[0m, in \u001b[0;36mProcessor.process.<locals>.make_1d_pt_hist_cat\u001b[0;34m(obj, reg_binning, cat_binning, var_name, cat_name)\u001b[0m\n\u001b[1;32m     34\u001b[0m obj_cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, cat_name)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#var1_binning = [ 1, 2, 3, 4, 5,\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#            6, 7, 8, 9, 10,\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#            11, 12, 13, 14, 15,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# can rebin later like:\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# hist[:, :10] → selects the first 10 bins in the second axis\u001b[39;00m\n\u001b[1;32m     44\u001b[0m hist \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     45\u001b[0m     \u001b[43mdah\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\n\u001b[0;32m---> 46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg_binning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;241m.\u001b[39mIntCat(cat_binning, name\u001b[38;5;241m=\u001b[39mcat_name)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m.\u001b[39mDouble()\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;241m.\u001b[39mfill(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;66;03m#eta=np.abs(ak.flatten(obj.eta)),\u001b[39;00m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{var_name: ak\u001b[38;5;241m.\u001b[39mflatten(obj_var),\n\u001b[1;32m     52\u001b[0m            cat_name:ak\u001b[38;5;241m.\u001b[39mflatten(obj_cat)\n\u001b[1;32m     53\u001b[0m         }\n\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hist\n",
      "\u001b[0;31mTypeError\u001b[0m: QuickConstruct.Regular() missing 2 required positional arguments: 'start' and 'stop'"
     ]
    }
   ],
   "source": [
    "import cloudpickle\n",
    "\n",
    "results = {}\n",
    "\n",
    "for AOD_type in run_on.keys():\n",
    "    for year in run_on[AOD_type]:\n",
    "        for sample_name in run_on[AOD_type][year]:\n",
    "            #print(run_on[AOD_type][year][sample_name].keys())\n",
    "            entry = run_on[AOD_type][year][sample_name]\n",
    "            print(f\"sample in json: {sample_name}\")\n",
    "            \n",
    "\n",
    "            if entry['run']:\n",
    "\n",
    "                preprocessed_file_path = (\n",
    "                    path_to_master_json / \n",
    "                    datasets[AOD_type][year][sample_name]['preprocessed_file']\n",
    "                )\n",
    "\n",
    "                with gzip.open(preprocessed_file_path, \"rt\") as f:\n",
    "                    preprocessed_file = json.load(f)\n",
    "\n",
    "                num_files = entry['num_files']\n",
    "                num_chunks = entry['num_chunks']\n",
    "\n",
    "                client = Client(\"tls://localhost:8786\")\n",
    "\n",
    "                if entry[\"use_client\"]:\n",
    "                    print(\"using client\")\n",
    "                else:\n",
    "                    client.close()\n",
    "                    \n",
    "                \n",
    "                if entry['reduced_computation']:\n",
    "                    test_files  = max_files(preprocessed_file, num_files)\n",
    "                    test_chunks = max_chunks(test_files, num_chunks)\n",
    "                \n",
    "                    tg, rep = apply_to_fileset(\n",
    "                        data_manipulation=Processor(),\n",
    "                        fileset=test_chunks,\n",
    "                        schemaclass=NanoAODSchema,\n",
    "                        uproot_options={\"allow_read_errors_with_report\": (OSError, KeyError)},\n",
    "                    )\n",
    "                else:\n",
    "                    tg, rep = apply_to_fileset(\n",
    "                        data_manipulation=Processor(),\n",
    "                        fileset=preprocessed_file,\n",
    "                        schemaclass=NanoAODSchema,\n",
    "                        uproot_options={\"allow_read_errors_with_report\": (OSError, KeyError)},\n",
    "                    )\n",
    "\n",
    "                #client.scheduler_info()\n",
    "                print(\"sample loaded, running, hold please.........\")\n",
    "                result, report = dask.compute(tg, rep)\n",
    "\n",
    "                pikl_result_path = Path('pikls') / processor_name\n",
    "                pikl_result_path.mkdir(parents=True, exist_ok=True)\n",
    "                with open(pikl_result_path / f\"{sample_name}.pkl\", \"wb\") as f:\n",
    "                    cloudpickle.dump(result, f)\n",
    "                \n",
    "                #ak.to_json(report[], f\"pikls/{sample_name}_{processor_name}_report.json\", num_indent_spaces=2)\n",
    "                print(f\"done with {sample_name}\")\n",
    "            else:\n",
    "                print('skipping')\n",
    "                continue\n",
    "if client.status == 'running':\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedecd2c-2d7e-4999-a38c-b7750ee8c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = result['SlepSnuCascade_MN1-270_MN2-280_MC1-275_TuneCP5_13p6TeV_madgraphMLM-pythia8130X_mcRun3_2023_realistic_postBPix_v6-v3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2669be2-073b-49d9-bbe5-be827b38852c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c80f87-b317-4401-97c3-092a1166d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34647da-cb28-4242-be20-97b1c0732a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "r['test_dict']['pt_eta_hist'].project('pt', 'qual_tag').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60edde09-e787-4f8c-9029-f4253302abed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0,17.5,20.0,22.5,25.0,27.5,30.0,32.5,35.0,37.5,40.0,42.5,45.0,47.5,50.0,52.5,55.0,57.5,60.0,62.5,65.0,67.5,70.0,72.5,75.0,77.5,80.0,82.5,85.0,87.5,90.0,92.5,95.0,97.5,100.0\n"
     ]
    }
   ],
   "source": [
    "values = [15 + 2.5 * i for i in range(int((100 - 15) / 2.5) + 1)]\n",
    "print(\",\".join(str(v) for v in values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322a33f-ae0a-41ac-93e0-e4857d2db24e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
